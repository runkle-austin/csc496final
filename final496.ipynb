{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc615f9-37fc-490d-80c2-b3edd8137aa9",
   "metadata": {},
   "source": [
    "Decision Transformer: Reinforcement Learning via Sequence Modeling\n",
    "Recreated by : Austin Runkle, \n",
    "\n",
    "In this project we will be implementing the decision transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c3d7b5-271c-4fb3-9bb7-6f679f7fba04",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14b4b9-5c8d-45c0-b9d7-df8ead470e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "004c203e-196d-44b1-a44f-08a6dc54a674",
   "metadata": {},
   "source": [
    "Decision Transformer - For Continuous Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f4ac4-ecac-4366-8bbb-f2b8de6c2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R, s, a, t: returns -to -go , states , actions , or timesteps\n",
    "# K: context length ( length of each input to DecisionTransformer )\n",
    "# transformer : transformer with causal masking (GPT)\n",
    "# embed_s , embed_a , embed_R : linear embedding layers\n",
    "# embed_t : learned episode positional embedding\n",
    "# pred_a : linear action prediction layer\n",
    "# main model\n",
    "def DecisionTransformer (R , s , a , t ):\n",
    "    # compute embeddings for tokens\n",
    "    pos_embedding = embed_t ( t ) # per - timestep ( note : not per - token )\n",
    "    s_embedding = embed_s ( s ) + pos_embedding\n",
    "    a_embedding = embed_a ( a ) + pos_embedding\n",
    "    R_embedding = embed_R ( R ) + pos_embedding\n",
    "    # interleave tokens as (R_1 , s_1 , a_1 , ... , R_K , s_K )\n",
    "    input_embeds = stack ( R_embedding , s_embedding , a_embedding )\n",
    "    # use transformer to get hidden states\n",
    "    hidden_states = transformer ( input_embeds = input_embeds )\n",
    "    # select hidden states for action prediction tokens\n",
    "    a_hidden = unstack ( hidden_states ). actions\n",
    "    # predict action\n",
    "    return pred_a ( a_hidden )\n",
    "# training loop\n",
    "for (R , s , a , t ) in dataloader : # dims : ( batch_size , K, dim )\n",
    "    a_preds = DecisionTransformer (R , s , a , t )\n",
    "    loss = mean (( a_preds - a )**2) # L2 loss for continuous actions\n",
    "    optimizer . zero_grad (); loss . backward (); optimizer . step ()\n",
    "# evaluation loop\n",
    "target_return = 1 # for instance , expert - level return\n",
    "R , s , a , t , done = [ target_return ] , [ env . reset ()] , [] , [1] , False\n",
    "while not done : # autoregressive generation / sampling\n",
    "    # sample next action\n",
    "    action = DecisionTransformer (R , s , a , t )[ -1] # for cts actions\n",
    "    new_s , r , done , _ = env . step ( action )\n",
    "    # append new tokens to sequence\n",
    "    R = R + [ R [ -1] - r] # decrement returns -to -go with reward\n",
    "    s , a , t = s + [ new_s ] , a + [ action ] , t + [ len ( R )]\n",
    "    R , s , a , t = R [ - K :] , ... # only keep context length of K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d36d07-6256-4613-b220-67328f47fd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74294a0f-d5ac-4cb8-8769-2b3cb291cdd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
